
		<div class="site-wrapper">
			<div class="site-wrapper-inner">
				<div class="cover-container">
					<div class="masthead clearfix">
						<div class="inner">
							<h3 class="masthead-brand"><img class="img" border="0" alt="ben" src="images/benlogo.png">Blog</h3>
							<nav>
								<ul class="nav masthead-nav">
									<li><a href="#/">Home</a></li>
									<li><a href="#/work">Work</a></li>
									<li class="active"><a href="#/blog">Blog</a></li>
									<li><a href="#/contact">Contact</a></li>
									
								</ul>
							</nav>
						</div>
					</div>

					<div class="inner cover">
						<h1 class="cover-heading">  </h1>

						<div class="panel panel-blog">
  							<div class="panel-body">
  								
  								<div class="container-fluid marketing">

		  							<img class="img-responsive" ng-src="{{blogs[0].image[0]}}" alt="Metafora" >
		  							<img class="img-responsive" ng-src="{{blogs[0].image[6]}}" alt="Metafora" >
		  							
	  								
	  								<h3>{{blogs[0].title}}</h3>
	  								<h5>{{blogs[0].subtitle}}</h5>
	  								<br/>
	  								<p><b>{{blogs[0].date}}</b> - If you're reading this you're interested in computer vision, or you're stalking me. Either way, over the next few weeks/months/years I am going to be posting blogs on OpenCV as I continue to self-teach myself about computer vision. If you're able to learn something from these blogs, great! Otherwise, thanks for stopping by. Let's get started.</p>
	  								<br/>
	  								<p>We're going to be working with OpenCV to create a simple program that utilizes Haar Cascades to find and track faces through our camera. We're assuming that you've already gone through the always fun process of building OpenCV on your machine and are ready to start using its libraries and dependancies in your IDE of choice. OpenCV allows you to use Python or Java just as easily, but I'm going to be working with the C family out of preference.</p>
	  								<br/>
	  								<p>The majority of people who end up here will not be interested in how this all works. They are here to cut and paste the code and start working on this for themselves. That's all fine. First, I'll do a brief breakdown of the code for these people. After, for the people who want to understand what's going on, I'll go into detail on what exactly a Haar Feature is, and how we make use of them in conjunction with a bunch of successive (also called cascading) pass/fail tests (also called classifiers) to find objects in images.</p>

	  								<br/>
	  								<b>Code Breakdown</b>
	  								<br/>
	  								<p>We'll #include:
	  								<br/>
	  								
									<a href="http://docs.opencv.org/3.1.0/d8/da3/objdetect_8hpp.html" target="_blank"><code class="language-cpp">objdetect.hpp</code></a> to access and use our Haar Cascade.
	  								<br/>
	  								<a href="http://docs.opencv.org/2.4/modules/highgui/doc/highgui.html" target="_blank"><code class="language-cpp">highgui.hpp</code></a> primarily to get access to attached Cameras and also to show our facial tracking window.
	  								<br/>
	  								<a href="http://docs.opencv.org/2.4.8/modules/imgproc/doc/imgproc.html" target="_blank"><code class="language-cpp">imgproc.hpp</code></a> to convert our color pictures to grayscale.
	  								<br/>
	  								</p>

	  								<pre class="prettyprint"><code class="language-cpp">
/*I've linked the official reference docs for these guys above. If you're using a Class/Header file, you should know what else it can do.*/
#include "opencv2/objdetect/objdetect.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
									</code></pre>

									<br/>
									<p>Let's start coding. Gameplan is as follows: first initialize vars (camera, haarcascade, and a place to store a single frame), second in a loop get a frame, third convert frame to grayscale, fourth use haarcascade to return any faces in our grayscale,  fifth loop through our returned faces and draw a rectangle over them, sixth repeat until signalled to close.</p>
									<br/>
									<pre class="prettyprint"><code class="language-cpp">
int main()
{
	/*I will be hard coding scope for practice and better understanding of what I'm building Objects from.
	If you do not understand or know what class I am instancing these objects from, click the links in the #include section.*/
	cv::VideoCapture wc;
	/*Open camera, close if we can't.*/
	if(!wc.open(0)) return 0;

	/*Set up our Haar Cascade. 
	haarcascade_frontalface_alt2.xml comes prepackaged with OpenCV. At the end of this blog we'll discuss creating your own.*/
	cv::CascadeClassifier frontal_face_cascade;
	frontal_face_cascade.load("/opencv/data/haarcascades/haarcascade_frontalface_alt2.xml");

	

	/*We're continuously looking for faces from our camera feed, so we use an infinite loop until we want to break.*/
	for(;;)
	{
		/*Initialize storage frame and read into it*/
		cv::Mat frame;
		wc.read(frame);

		/*Convert to grayscale*/
		cv::Mat g_value;
		cvtColor(frame, g_value, CV_BGR2GRAY);

		/*Store faces found in vector*/
		std::vector < cv::Rect_< int > > faces;
		/*Detect faces FROM g_value and store in our vectore faces*/
		frontal_face_cascade.detectMultiScale(g_value, faces);

		/*Iterate and draw rectangle around each face*/
		for(int i = 0; i < faces.size(); i ++)
		{
			/*Get current face*/
			cv::Rect face_i = faces[i];

			/*Draw rectangle on our frame*/
			rectangle(frame, face_i, CV_RGB(255,0,0), 1);

			/*Not needed, but draw text over rectangle to show face count*/
			int pos_x = std::max(face_i.tl().x - 10, 0);
			int pos_y = std::max(face_i.tl().y - 10, 0);
			putText(frame, "Face " + std::to_string(i), cv::Point(pos_x, pos_y), cv::FONT_ITALIC, 1.0, CV_RGB(255,0,0), 2.0);
		}
		/*Show window with frame*/
		imshow("facial_recognition", frame);

		/*End if any key is pressed*/
		int key = cv::waitKey(1);
		if(key != -1) break;
	}

	cv::waitKey(0);
	return 0;
}
									</code></pre>

									<br/>
									<p>Not too bad, right? Get a frame from a camera, convert to grayscale, Haar Cascade for faces, put a marker where the face is, and repeat. That's it. So if you're just here for the code, there you go. I've placed a link to my GitHub above where you can fork this project as well.</p>
									<br/>
									<b>How It Works</b>
									<br/>
									<p>How exactly does a machine take a bunch of grayscale values and decide whether or not they contain a human face? Let's break this down. For humans, it is just intuitive to see a face and recognize it. We see a nose, ears, eyes, cheek bones, a chin, hair, etc. We see features. Computers see images as pixels which are stored in some variation of a 2D or 3D array depending on format and content. Our features are in these arrays.</p>
									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[3]}}" alt="Pixel representation of image">
										</div>
										<p>The picture shown on the left is greatly simplified. It shows how a tiny color image is stored in a computer. If we want to scan this image for its yellow area we could return all array indexes where the indexed value is 5. We just found all yellow pixels in our image. Bringing this small example to our current problem, we are scanning much larger arrays for indexes that return the value of a human face.
										</p> 
										<br/>
										<p>
										The question is what value does a human face have? We got the answer in 2001 from Paul Viola and Michael Jones in their paper "Rapid Object Detection using a Boosted Cascade of Simple Features." Human faces have many values, and when put (cascaded) through many consecutive pass or fail tests (classifiers) we can determine whether or not we have a human face in our image.
										</p>
									</div>
									<br/>

									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[1]}}" alt="Metafora">
										</div>
										<p>
											These classifiers make use of differences found in small chunks of pixels within images when compared with one another. Remember we are looking at pictures, meaning very large arrays. We break the array into smaller pieces that are easier to work with. To compare these small chunks we make use of Haar Wavelet-like shapes. A Haar Wavelet is a square shaped sequence of a function. We can use and shift these wavelets to represent other bigger functions if we so desire. This is useful when discussing image compression. For this blog, we are only really interested in the rectangular shape of the Haar Wavelet. our Haar Wavelet-like Features come into play as we attempt to compare chunks of pixels with other chunks. To the left, we can see the 3 original rectangular shapes used by Viola and Jones. Edge, line, and four rectangle features. If we place a Haar-like Feature over an image, we can sum the indexed pixel values within our black rectangle and white rectangle allowing for comparisons to be made between the two. One rectangle may have a lower sum value, a higher sum value, or be equal with the other. This gives us a place to start. We've got a way to compare parts of our images now.
										</p>
									</div>
									<br/>

									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[4]}}" alt="Metafora">
										</div>
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[5]}}" alt="Metafora">
										</div>
										<p>
											But hold on, we're dealing with really big pictures here and lots of pixels... Isn't summing the pixels inside a rectangle every time we do a Haar Feature Classifier going to be really slow? Yes, and especially when we sum large sections of an image. The solution is the Integral Image, also known as a Summed Area Table. At the start of our Haar Cascade, we calculate the rectangular sum of every pixel, meaning we add every pixel above and to the left of our current index in the array. The image on the left shows an example 2D image array with values, followed by its Integral Image.
											<br>
											<br>
											As seen in the orignal image, we begin in the upper left with a rectangle of 1x1 and sum our current pixel with value 1 with all pixels above and left forming a rectangle. We do not have any pixels above or left, so we are left with a value of just 1. Next, we move stepwise to our next column in row and begin with a value of 5. We sum 5 with every pixel above and left of our current index giving us a value 5 + 1 = 6. We've reached the end of columns for row 1, so we move to row 2 and begin again. We start with our current value index value of 2 and sum values above and left giving us 2 + 1 = 3. Finally, we move stepwise to our next column in row and begin with a value of 4. We sum values above and left giving us 4 + 5 + 2 + 1 = 12. These are the values of are new Integral Image. Once summed, the intensity of any rectangular area within the image can be calculated with just four operations.
										</p>
										<br/>
										<p>
											Looking at the second image on our left, we see the process we go through to get the intensity of values within our rectangle. We're not summing every value inside of our rectangle. We're performing calculations on the corners only. No matter if our rectangle is 4x4 pixels, or 24x24 pixels, at most we will perform 4 operations using the indexed values of our Integral Image and get the summed values we need. So, we have a place to start and we have a fast method of calculation.
										</p>
									</div>
									<br/>

									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[2]}}" alt="Metafora">
										</div>

										<p>
											The next step is realizing that we can use these Haar-like features to analyze a human face. That is not immediately intuitive. How can we use a rectangle to analyze a human face? As seen in the pictures on the left, we can place our Haar Features over different parts of a human face and get accurate, consistent results. For example, if we use our Edge Feature shape we can compare the area around the eyes with the area below and note that a face will show smaller, darker values around the eyes and higher, brighter values beneath and on the cheeks. Using our Integral Image terms, the sum of the pixel values in the rectangle containing eyes will consistently be less (meaning darker) than the sum of the rectangle containing the upper cheek area. These consistent patterns are called classifiers. And, when tested in a cascading manner over many classifiers we have our method. It is important to remember, these classifiers can also be used to find features in any object we want to look for in an image.
											<br>
											<br>
											People have cycled through thousands of images of a target object and found average values of Haar-features when placed at different locations and sizes over an image. They have also cycled through thousands of images of non target objects and found averages to compare what they do not want to recognize. This set of positive image values and negative image values forms what we call a Haar Cascade. We can use the trained Haar Cascade in our applications now and use its classifiers to scan over and compare different sections of our image. If we find a match of all classifiers, we know that our image will contain the object we are searching for. If at any point it fails one classifier, we know that this portion of our picture does not contain the object and we continue to look over the remainder of the image until we finish scanning all possible areas.

										</p>
									</div>
									<br/>
									<br/>
									<div class="blog_horizontal_parent">
										<p>
											The original Haar Cascade used 200 classifier features to achieve a 95% detection rate. Some applications will need a higher detection rate, or might not care. Based on your needs you may use a higher number of classifier features for a more accurate result or a lower number of classifier features for a faster computation time. And with that, we've reached the conclusion of my brief and simplified explanation of Haar Feature-based Cascade Classifiers. Hopefully you've learned something along the way. I encourage you to grab OpenCV, experiment with this code, and look at how others have used this same method in other applications. Additionally, feel free to contact me with comments and questions.
											<br/>
											<br/>
											<a href="mailto:benjaminjkrig@gmail.com" class="btn btn-lg btn-default">benjaminjkrig@gmail.com</a>
											-Ben Krig
										</p>
									</div>

								</div>
  							</div>
						</div>

						<div class="mastfoot">
							<div class="inner">
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>