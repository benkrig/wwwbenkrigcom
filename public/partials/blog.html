
		<div class="site-wrapper">
			<div class="site-wrapper-inner">
				<div class="cover-container">
					<div class="masthead clearfix">
						<div class="inner">
							<h3 class="masthead-brand"><img class="img" border="0" alt="ben" src="images/benlogo.png">Blog</h3>
							<nav>
								<ul class="nav masthead-nav">
									<li><a href="#/">Home</a></li>
									<li><a href="#/work">Work</a></li>
									<li class="active"><a href="#/blog">Blog</a></li>
									<li><a href="#/contact">Contact</a></li>
									
								</ul>
							</nav>
						</div>
					</div>

					<div class="inner cover">
						<h1 class="cover-heading">  </h1>

						<div class="panel panel-blog">
  							<div class="panel-body">
  								
  								<div class="container-fluid marketing">

		  							<img class="img-responsive" ng-src="{{blogs[0].image[0]}}" alt="Metafora" >
	  								
	  								<h3>{{blogs[0].title}}</h3>
	  								<h5>{{blogs[0].subtitle}}</h5>
	  								<p><b>{{blogs[0].date}}</b> - If you're reading this you're interested in computer vision, or you're stalking me. Either way, over the next few weeks/months/years I am going to be posting blogs on OpenCV as I continue to self-teach myself about computer vision. If you're able to learn something from these blogs, great! Otherwise, thanks for stopping by. Let's get started.</p>
	  								<br/>
	  								<p>We're going to be working with OpenCV to create a simple program that utilizes Haar Cascades to find and track faces through our camera. We're assuming that you've already gone through the always fun process of building OpenCV on your machine and are ready to start using its libraries and dependancies in your IDE of choice. OpenCV allows you to use Python or Java just as easily, but I'm going to be working with the C family out of preference.</p>
	  								<br/>
	  								<p>The majority of people who end up here will not be interested in WHY/HOW this all works. They'll just be here to cut and paste the code and start working on this for themselves. That's all fine. First, I'll do a brief breakdown of the code for these people. Finally, at the end of this blog I'll try to go into detail on what exactly a Haar Feature is, and how we can make use of them in conjunction with a bunch of successive (also called cascading) pass/fail tests (also called classifiers) to find objects in images.</p>

	  								<br/>
	  								<b>Code Breakdown</b>
	  								<br/>
	  								<p>We'll #include:
	  								<br/>
	  								
									<a href="http://docs.opencv.org/3.1.0/d8/da3/objdetect_8hpp.html" target="_blank"><code class="language-cpp">objdetect.hpp</code></a> to access and use our Haar Cascade.
	  								<br/>
	  								<a href="http://docs.opencv.org/2.4/modules/highgui/doc/highgui.html" target="_blank"><code class="language-cpp">highgui.hpp</code></a> primarily to get access to attached Cameras and also to show our facial tracking window.
	  								<br/>
	  								<a href="http://docs.opencv.org/2.4.8/modules/imgproc/doc/imgproc.html" target="_blank"><code class="language-cpp">imgproc.hpp</code></a> to convert our color pictures to grayscale.
	  								<br/>
	  								</p>

	  								<pre class="prettyprint"><code class="language-cpp">
/*I've linked the official reference docs for these guys above. If you're using a Class/Header file, you should know what else it can do.*/
#include "opencv2/objdetect/objdetect.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
									</code></pre>

									<br/>
									<p>Let's start coding. Gameplan is as follows: first initialize vars (camera, haarcascade, and a place to store a single frame), second in a loop get a frame, third convert frame to grayscale, fourth use haarcascade to return any faces in our grayscale,  fifth loop through our returned faces and draw a rectangle over them, sixth repeat until signalled to close.</p>
									<br/>
									<pre class="prettyprint"><code class="language-cpp">
int main()
{
	/*I will be hard coding scope for practice and better understanding of what I'm building Objects from.
	If you do not understand or know what class I am instancing these objects from, click the links in the #include section.*/
	cv::VideoCapture wc;
	/*Open camera, close if we can't.*/
	if(!wc.open(0)) return 0;

	/*Set up our Haar Cascade. 
	haarcascade_frontalface_alt2.xml comes prepackaged with OpenCV. At the end of this blog we'll discuss creating your own.*/
	cv::CascadeClassifier frontal_face_cascade;
	frontal_face_cascade.load("/opencv/data/haarcascades/haarcascade_frontalface_alt2.xml");

	

	/*Start our continuous loop.*/
	for(;;)
	{
		/*Initialize storage frame and read into it*/
		cv::Mat frame;
		wc.read(frame);

		/*Convert to grayscale*/
		cv::Mat g_value;
		cvtColor(frame, g_value, CV_BGR2GRAY);

		/*Store faces found in vector*/
		std::vector < cv::Rect_< int > > faces;
		/*Detect faces FROM g_value and store in our vectore faces*/
		frontal_face_cascade.detectMultiScale(g_value, faces);

		/*Iterate and draw rectangle around each face*/
		for(int i = 0; i < faces.size(); i ++)
		{
			/*Get current face*/
			cv::Rect face_i = faces[i];

			/*Draw rectangle on our frame*/
			rectangle(frame, face_i, CV_RGB(255,0,0), 1);

			/*Not needed, but draw text over rectangle to show face count*/
			int pos_x = std::max(face_i.tl().x - 10, 0);
			int pos_y = std::max(face_i.tl().y - 10, 0);
			putText(frame, "Face " + std::to_string(i), cv::Point(pos_x, pos_y), cv::FONT_ITALIC, 1.0, CV_RGB(255,0,0), 2.0);
		}
		/*Show window with frame*/
		imshow("facial_recognition", frame);

		/*End if any key is pressed*/
		int key = cv::waitKey(1);
		if(key != -1) break;
	}

	cv::waitKey(0);
	return 0;
}
									</code></pre>

									<br/>
									<p>Not too bad, right? Get frame from camera, go to grayscale, Haar Cascade for faces, draw rectangles on and show the frame. That's it. So if you're just here for the code, there you go. I've placed a link to my Github above where you can fork this project as well. </p>
									<br/>
									<b>How It Works</b>
									<br/>
									<p>How exactly do we get a machine to take a bunch of grayscale values and decide whether or not they contain a human face? For humans it is just intuitive to see a face and recognize it. We see a nose, ears, eyes, cheek bones, a chin, hair, etc. We see features. Computers see images as pixels, usually as a 2D Array of color values.</p>
									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[3]}}" alt="Pixel representation of image">
										</div>
										<p>The picture shown on the left is greatly simplified, but does an adequate job of showing how a tiny color image is stored in a computer. On the topic of computer vision, if we want to scan this image for yellow area we could return all array indexes where the value at index is 5. We have found all yellow pixels in our image. Bringing this small example to our current problem, we are scanning much larger arrays for indexes that return the value of a human face.
										</p> 
										<br/>
										<p>
										The question is what value does a human face have? We got the answer in 2001 from Paul Viola and Michael Jones in their paper "Rapid Object Detection using a Boosted Cascade of Simple Features." Human faces have many values, and when put (cascaded) through many consecutive pass or fail tests (classifiers) we can determine whether or not we have a human face in our image.
										</p>
									</div>
									<br/>

									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[1]}}" alt="Metafora">
										</div>
										<p>
											These classifiers make use of the differences found in small chunks of our image when compared with one another. Remember we are looking at very large 2D arrays, we break the array into smaller pieces to more easily work with. To compare these small chunks we make use of Haar Wavelet-like shapes (All you need to know about the Haar Wavelet is that is shaped like a rectangle). To the left, we can see the 3 original shapes used by Viola and Jones. Edge, line, and four rectangle features. If we place one these shapes over an image, we can sum the values of pixels within our black rectangle and white rectangle allowing for comparisons to be made between the two. One rectangle may be lighter, darker, or they may be the same. This gives us a place to start. We've got a method now to test portions of our image for a face.
										</p>
									</div>
									<br/>

									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[4]}}" alt="Metafora">
										</div>
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[5]}}" alt="Metafora">
										</div>
										<p>
											But hold on, we're dealing with really big pictures here and lots of pixels... Isn't summing the pixels every time we do a Haar Feature Classifier going to be really slow? Yes it would. The solution is the Integral Image. I'm not going to go into too much depth on this, however. Essentially, at the start of our Haar Cascade, we calculate the rectangular sum of every pixel in the image. The result looks something like the image on the left. With this new set of values we can calculate the rectangular area of any subset of indexes using this one Integral Image. We don't need to sum over thousands of pixels every time. That means this is pretty fast.
										</p>
										<br/>
										<p>
											Looking at the second image on our left, we see the process we go through to get the sum of our rectangles. We're not adding every value inside of our rectangle. No matter the size of our rectangle, we only use 4 operations with values from our Integral Image to get to the summed values for the original image. This is huge for processing and speed.
										</p>
										<br/>
										<p>So, we've got an image and we've found an efficient way to compare little chunks of it.</p>
									</div>
									<br/>

									<br/>
									<div class="blog_horizontal_parent">
										<div class="blog_horizontal">
											<img class="img-responsive" ng-src="{{blogs[0].image[2]}}" alt="Metafora">
										</div>

										<p>
											The next step is realizing that we CAN actually use these Haar-like features to analyze a human face. As seen in the pictures on the left, we can place our Haar Features over different parts of the face and get accurate, consistent results. For example, if we use our Edge Feature shape we can compare the area around the eyes with the area below and note that a face will show smaller, darker values around the eyes and higher, brighter values beneath and on the cheeks. Using our Integral Image terms, the sum of the pixel values in the rectangle containing eyes will consistently be less than the sum of the rectangle containing the upper cheek area. These consistent patterns are called classifiers. And, when tested in a cascading manner over many classifiers we have our method. The original Haar Feature Cascade Classifier used 200 features to achieve a detection rate 95%. You might need a higher rate, or might not care. Based on your needs you may use a higher number of features for a more accurate result or a lower number for faster computation time. -- Writing in Progress --
										</p>
									</div>
									<br/>

	  								UNDER CONSTRUCTION
								</div>
  							</div>
						</div>

						<div class="mastfoot">
							<div class="inner">
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>